# YOLOv11 Instance Segmentation in Adverse Weather

![Project Status](https://img.shields.io/badge/status-completed-green)

This repository contains the complete project for the "YOLOv11 Instance Segmentation and Model Evaluation in Adverse Conditions" assignment for the Computer Science Department at Iran University of Science and Technology. The project involves generating a synthetic dataset using the **CARLA simulator**, training and evaluating three variants of the **YOLOv11-seg** model, and analyzing their performance on instance segmentation tasks under various weather conditions.



## Table of Contents
- [YOLOv11 Instance Segmentation in Adverse Weather](#yolov11-instance-segmentation-in-adverse-weather)
  - [Table of Contents](#table-of-contents)
  - [Project Overview](#project-overview)
  - [Key Features](#key-features)
  - [Trained Models](#trained-models)
  - [Project Structure](#project-structure)
  - [Getting Started](#getting-started)
    - [Prerequisites](#prerequisites)
    - [Installation](#installation)
  - [Workflow and Usage](#workflow-and-usage)
    - [Step 1: Dataset Generation](#step-1-dataset-generation)
    - [Step 2: Data Pre-processing](#step-2-data-pre-processing)
    - [Step 3: Model Training](#step-3-model-training)
    - [Step 4: Model Evaluation](#step-4-model-evaluation)
    - [Step 5: Model Optimization (Optional)](#step-5-model-optimization-optional)
  - [Results and Analysis](#results-and-analysis)
    - [Evaluation Summary](#evaluation-summary)
    - [Key Findings](#key-findings)
  - [Conclusion](#conclusion)
  - [Future Work](#future-work)
  - [Acknowledgments](#acknowledgments)

## Project Overview

The primary goal of this project is to assess the robustness of the YOLOv11-seg architecture for autonomous driving perception. We evaluate its ability to perform instance segmentation on four critical object classes (`car`, `bus`, `pedestrian`, `traffic_light`) under four challenging weather scenarios (`Day`, `Night`, `Rain`, `Fog`).

The project pipeline covers:
1.  **Dataset Generation:** Creating a synchronized RGB and instance segmentation dataset in CARLA.
2.  **Data Pre-processing:** Converting CARLA annotations to the YOLOv11 format and splitting the data.
3.  **Model Training:** Training YOLOv11n-seg, YOLOv11m-seg, and YOLOv11l-seg models.
4.  **Evaluation:** Systematically testing the models on each weather condition to measure mAP and inference speed.
5.  **Optimization:** Exploring post-training quantization and TensorRT conversion to improve deployment efficiency.

## Key Features

- **Synthetic Data Generation:** A robust Python script (`1_carla_data_collector.py`) to generate complex, multi-weather datasets from CARLA.
- **Automated Pre-processing:** A comprehensive script (`2_yolo_data_preprocessor.py`) to convert, split, and validate the dataset for YOLOv11.
- **Comparative Model Training:** Scripts to train nano, medium, and large variants of YOLOv11-seg.
- **Granular Evaluation:** A detailed evaluation pipeline to test model performance on separate weather-specific test sets.
- **Performance Optimization:** Includes scripts for INT8 quantization and TensorRT benchmarking to simulate a real-world deployment workflow.

## Trained Models
https://drive.google.com/file/d/1FJlD8G93357Z-cuRHB4xnT66y-Tx1CKk/view?usp=sharing

## Project Structure

```
.
├── 1_carla_data_collector.py      # Script to generate dataset from CARLA
├── 2_yolo_data_preprocessor.py    # Converts CARLA data to YOLO format, splits dataset
├── 3_train_models/                # Training scripts
│   ├── train_nano.py
│   ├── train_medium.py
│   └── train_large.py
├── 4_create_weather_yamls.py      # Creates separate test sets for each weather condition
├── 5_evaluate_models.py           # Evaluates all trained models on all weather conditions
├── 6_optimize_model.py            # Script for post-training quantization (FP32 -> INT8)
├── 7_benchmark_tensorrt.py        # Compares PyTorch and TensorRT pipeline speeds
├── 8_tensorrt.sh                  # Shell script to convert .onnx to a TensorRT engine
│
├── carla_dataset/                 # Raw dataset generated by CARLA (images, JSON annotations)
├── yolo_dataset/                  # Processed dataset in YOLOv11 format
├── carla_yolo_training_result/    # Output directory for model weights, logs, and plots
│
├── evaluation_summary.csv         # Final evaluation results in CSV format
├── requirements.txt               # Python dependencies
└── README.md                      # This file
```

## Getting Started

### Prerequisites
- [CARLA Simulator](https://carla.readthedocs.io/en/latest/start_quick_start/) (Version 0.9.11 or newer recommended)
- Python 3.8+
- NVIDIA GPU with CUDA and cuDNN installed
- [TensorRT](https://developer.nvidia.com/tensorrt) (for the optimization part)

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/MSPoulaei/carla-instance-segmentation.git
    cd carla-instance-segmentation
    ```

2.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Setup CARLA:**
    - Download and extract the CARLA simulator.
    - Run the simulator:
      ```bash
      # On Linux
      ./CarlaUE4.sh
      # On Windows
      CarlaUE4.exe
      ```
    - Ensure the CARLA Python API is accessible. You may need to add the `.egg` file to your `PYTHONPATH`.

## Workflow and Usage

Follow these steps to replicate the project pipeline.

### Step 1: Dataset Generation
Run the data collection script. This will connect to the running CARLA instance, spawn vehicles and pedestrians, and save synchronized RGB and segmentation data.

```bash
python 1_carla_data_collector.py
```
This will create the `carla_dataset/` directory populated with images and JSON annotations for all four weather conditions.

### Step 2: Data Pre-processing
Convert the raw CARLA data into the YOLOv11 segmentation format. This script also splits the dataset into train/val/test sets (60/20/20 split) and creates the `dataset.yaml` file.

```bash
python 2_yolo_data_preprocessor.py
```
This generates the `yolo_dataset/` directory, ready for training.

### Step 3: Model Training
Train the three model variants. Run each script separately. The training process will use the `yolo_dataset/` and save all outputs (weights, logs, plots) to the `carla_yolo_training_result/` directory.

```bash
# Train the nano model
python 3_train_models/train_nano.py

# Train the medium model
python 3_train_models/train_medium.py

# Train the large model
python 3_train_models/train_large.py
```

### Step 4: Model Evaluation
First, create the weather-specific test configurations:
```bash
python 4_create_weather_yamls.py
```
Then, run the main evaluation script. It will load the best-trained weights for each model and test them against each weather-specific dataset.
```bash
python 5_evaluate_models.py
```
The results will be printed to the console and saved in `evaluation_summary.csv`.

### Step 5: Model Optimization (Optional)

**A. Quantization:**
To quantize the best nano model and compare its performance with the FP32 version, run:
```bash
python 6_optimize_model.py
```

**B. TensorRT Conversion & Benchmarking:**
First, use the `trtexec` command-line tool (provided with TensorRT) to convert the ONNX model to a TensorRT engine.
```bash
# Ensure the .onnx file exists from the previous step
bash 8_tensorrt.sh
```
Then, run the benchmark script to compare the end-to-end pipeline speed of PyTorch vs. TensorRT.
```bash
python 7_benchmark_tensorrt.py
```

## Results and Analysis

### Evaluation Summary
The final performance of the three models on the test set is summarized below. The primary metrics are segmentation **mAP@50-95** and average **Inference Time** on an NVIDIA RTX 3060.

| Model        | Weather | mAP@50-95 | mAP@50 | Inference Time (ms) |
| ------------ | ------- | --------- | ------ | ------------------- |
| YOLOv11n-seg | Day     | 0.5659    | 0.7670 | 10.64               |
| YOLOv11n-seg | Night   | 0.5659    | 0.7670 | 9.82                |
| YOLOv11m-seg | Day     | 0.5781    | 0.7925 | 19.00               |
| YOLOv11m-seg | Night   | 0.5781    | 0.7925 | 18.55               |
| YOLOv11l-seg | Day     | 0.5802    | 0.7745 | 22.22               |
| YOLOv11l-seg | Night   | 0.5802    | 0.7745 | 21.54               |
*(Note: Table shows a subset of results for brevity. Full results are in `evaluation_summary.csv`.)*

### Key Findings
1.  **Performance vs. Speed Trade-off:** The **YOLOv11m-seg** model offered the best balance. It achieved a significant accuracy boost over the nano model without the high latency of the large model.
2.  **Impact of Class Imbalance:** All models struggled with the `traffic_light` class, which had only 40 instances in the entire dataset. This highlights the critical importance of a balanced dataset for reliable performance across all classes.
3.  **Adverse Weather Effects:** While all models showed robust performance, a slight degradation in accuracy is expected in night, rain, and fog conditions compared to clear daytime scenes.
4.  **Optimization Benefits:** Post-training INT8 quantization significantly reduced model size and improved inference speed. Converting to a **TensorRT engine** provided the fastest possible inference, making it ideal for real-time deployment on edge devices.

## Conclusion
This project successfully demonstrates a full pipeline for evaluating deep learning models for autonomous driving perception. We confirmed that the YOLOv11-seg architecture is highly capable, with the medium variant providing a practical sweet spot for deployment. The study also reinforces that dataset quality, balance, and diversity are paramount for building robust systems that can handle real-world challenges like adverse weather.

## Future Work
- **Address Class Imbalance:** Implement targeted augmentation techniques like copy-paste to increase the number of samples for under-represented classes.
- **Expand Dataset:** Collect more data, especially for night, fog, and rain conditions, to further improve model robustness.
- **Real-World Validation:** Test the trained models on real-world datasets (e.g., BDD100K, Cityscapes) to see how well the simulator-based findings generalize.
- **Explore Other Architectures:** Compare YOLOv11's performance against other state-of-the-art instance segmentation models.

## Acknowledgments
This project was completed as part of an assignment for the Computer Science Department at **Iran University of Science and Technology**. Special thanks to **Dr. Abdollah Amirkhani** and **Amir Khosravian** for their guidance and for designing this insightful project.